{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW03 Sentiment Analysis with FNN, RNN, GRU and LSTM\n",
    "-- by Ruijie Rao"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "Regarding cleaning and loading data, I lowered the cases, cleaned out non-alphabetical characters and decontracted. Then, to improve efficiency in further works, I sampled the dataset then pickled it into a pkl file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Word2Vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Import Google News model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first checked the model's coverage of my corpus vocab by creating a Bag of Words with counts. Then, for every word in my vocab, I check if it is covered by the google model. Finally, sum the counts together to get the total coverage of text.\n",
    "\n",
    "In the first pass, only 70% of the total text are covered, which is pretty bad. Thus, I skimmed through the words that are not covered sorted in descending order of counts, found out that stopwords like \"and', \"of\", \"to\" are not covered while having huge counts in my corpus. After removing them, the coverage reached 98% though only 50% of the words are covered. Those are the words that are misspelled or very rare, so I let them be."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Semantic Similarities\n",
    "I used the L2 norm as the measurement of distance between 2 vectors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \"Cat\", \"Car\", and \"Bus\"\n",
    "\n",
    "    - Comparing \"car\" with both \"cat\" and \"bus\" explores if the word vector captures the semantic difference over edit distance.\n",
    "    - Result: \n",
    "        - Cat&Car: 3.5739133148105315\n",
    "        - Bus&Car: 2.9155472320880684\n",
    "    - It is shown that \"bus\" is actually more similar to \"car\" than \"cat\" to \"car\". Passed.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. King − Man + Woman = Queen\n",
    "    - This checks the semantic operation if holds.\n",
    "    - Result:\n",
    "        - King − Man + Woman vs. Queen: 2.298657801924729\n",
    "        - King vs. Queen: 2.479692373238762 (as a reference)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. excellent ∼ outstanding\n",
    "    - Result:\n",
    "        - excellent vs. outstanding: 2.4881580884687127\n",
    "        - excellent vs. terrible: 2.957787185080837\n",
    "    - Tested if the distance between similar words are closer than opposite words. Passed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build my own model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model according to this [tutorial](https://www.tutorialspoint.com/gensim/gensim_creating_a_dictionary.htm) and following the requirements in the hw-instruction: \"Set the embedding size to be 300 and the window size to be 13. You can also consider\n",
    "a minimum word count of 9.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check Semantic Similarities\n",
    "I used the L2 norm as the measurement of distance between 2 vectors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. King − Man + Woman = Queen\n",
    "    - This checks the semantic operation if holds.\n",
    "    - Result:\n",
    "        - King − Man + Woman vs. Queen: 4.871180486922247\n",
    "        - King vs. Queen: 1.5191899898462256 (as a reference)\n",
    "    - The \"Made up\" Queen is actually so far from Queen itself that even the word King is closer to Queen. Failed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. excellent ∼ outstanding\n",
    "    - Result:\n",
    "        - excellent vs. outstanding: 10.07535627275851\n",
    "        - excellent vs. terrible: 11.696851275335957\n",
    "    - The distance is so large, though it is closer than opposite word. Half-passed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Conclusion\n",
    "- In the King and Queen test, my model does terribly since the \"made up queen\" has a bigger distance from the actually queen than king itself.\n",
    "- In the excellent ∼ outstanding test, the result is also not satisfying, though atleast excellent and outstanding is more similar than exceleent and terrible.\n",
    "- To conclude, it is obvious that the google news pretrained model performs much better and more aligned with common sense. I do believe this is due to its huge corpus and difference in context. Google news definitely contains more semantic information than limited amount of product reviews."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Perceptron Model: \n",
    "    - TFIDF: Precision: 0.6866362883623626, Recall: 0.6598754678793339, F-1: 0.6648885837753792, **Accuracy: 0.6600833333333334**\n",
    "    - Word2Vec: Precision: 0.6598653875356274, Recall: 0.6036417528177076, F-1: 0.6021460529466545, **Accuracy: 0.60375**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM Model: \n",
    "    - TFIDF: Precision: 0.7062674968978809, Recall: 0.7082192621000024, F-1: 0.7068133498932015, **Accuracy: 0.7076666666666667**\n",
    "    - Word2Vec: Precision: 0.7035451625004853, Recall: 0.7070133675657541, F-1: 0.7035801054315015, **Accuracy: 0.70625**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- For perceptron model, TFIDF works obviously better than word2vec embeddings.\n",
    "- For SVM, both work equally well.\n",
    "- Comparing the two models, SVM outperforms Perceptron in both input types."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feedforward Neural Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Dataloader\n",
    "Build a dataset class that takes a input of a 2 column dataframe, the first column should be the feature (either mean or concat version of embeddings) while the second column should be the label. Feature array should be of dtype float32. \n",
    "\n",
    "Build a function that takes a whole dataframe and splits it into train, validation and test(0.6, 0.2, 0.2) and load them into seperate dataset loaders with a default batch size of 64.\n",
    "\n",
    "Different batch sizes are tried, finding that smaller batches mildly solves overfitting problems, though its unstability requires a smaller step size/ learning rate and thus more epochs. Batch size of 32-64 and learning rate of 0.001 is best."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Validation set and Best model\n",
    "I use a validation set to check for overfitting during the training process. Moreover, the model performance on validation set indicates which model state is the best. I save the best performing model on validation set and loads it as the final version that is tested with the testing set. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 FNN\n",
    "Built a FNN MLP following the instruction in [this](https://www.kaggle.com/mishra1993/pytorch-multi-layer-perceptron-mnist) tutorial. The FNN is composed of input layer (300), hidden layer 1 (100), hidden layer 2 (10), and output layer (3). Following each hidden layer, there is a relu (for non-linearity purpose accelerates descending) and dropout layer (for reducing overfitting). Finally, log-softmax is used on the output vector."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Mean Embedding vs. Concat Embedding\n",
    "- Mean Embedding: 0.71875\n",
    "- Concat Embedding: 0.6965\n",
    "\n",
    "### Conclusion\n",
    "Mean Embedding outperforms concat version. This may be because for mean embedding, all information are whole though not distinct. But for concat, not all information are included.\n",
    "\n",
    "FNN outperforms single perceptron model while doing a bit better than SVM."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recurrent Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 RNN\n",
    "The RNN is composed of input layer (300), hidden RNN layer (20), and output layer (3). Following the hidden layer, there is a dropout layer (for reducing overfitting). Finally, log-softmax is used on the output vector. The initial hidden state h0 is created as a zero tensor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: 0.728"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 GRU\n",
    "The GRU is composed of input layer (300), hidden GRU layer (20), and output layer (3). Following the hidden layer, there is a dropout layer (for reducing overfitting). Finally, log-softmax is used on the output vector. The initial hidden state h0 is created as a zero tensor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: 0.74075"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 LSTM\n",
    "The LSTM is composed of input layer (300), hidden LSTM layer (20), and output layer (3). Following the hidden layer, there is a dropout layer (for reducing overfitting). Finally, log-softmax is used on the output vector. The initial hidden state and cell state h0,c0 are created as zero tensors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result**: 0.73758"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "- Comparing within RNN models, GRU > LSTM > simple RNN regarding accuracy. \n",
    "- Comparing RNN against other models above, RNN models are definitely the best performing choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import pickle\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = ''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(DATA_DIR+\"sampled_df.pkl\",\"rb\") as file:\n",
    "    #sampled_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_table(DATA_DIR+'amazon_reviews_us_Beauty_v1_00.tsv.gz', compression='gzip', quotechar='\"', error_bad_lines=False, quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df[[\"star_rating\",\"review_body\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_class(x):\n",
    "    if x<3:\n",
    "        return 0\n",
    "    if x>3:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"star_rating\"].apply(label_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = pd.concat([df[df[\"label\"] == k].sample(n=20000) for k in range(3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(sampled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### contraction dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "    \"dont\":\"do not\",\n",
    "    \"ain't\": \"are not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\"\n",
    "    # More..\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decontract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontract(x):\n",
    "    tokens = x.split(' ')\n",
    "    for i,token in enumerate(tokens):\n",
    "        if token in contractions.keys():\n",
    "            tokens[i] = contractions[token]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(x):\n",
    "    my_stopwords = [\"a\", \"and\", \"of\", \"to\"]\n",
    "    x = x.lower() #convert all reviews into lowercase\n",
    "    x = re.sub(r'<br />', '', x)\n",
    "    x = re.sub(r'\\s*https?://\\S+(\\s+|$)', '', x) #remove the HTML and URLs from the reviews\n",
    "    x = re.sub(r'[^a-zA-Z ]+', ' ', x) #remove non-alphabetical characters\n",
    "    x = ' '.join(re.sub(r'\\s', ' ', x).split()) #remove extra spaces\n",
    "    x = ' '.join([word for word in x.split(\" \") if word not in my_stopwords])\n",
    "    x = decontract(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[\"review_cleaned\"] = sampled_df[\"review_body\"].apply(data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR+\"sampled_df.pkl\",\"wb\") as file:\n",
    "    pickle.dump(sampled_df, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "gg_model = api.load('word2vec-google-news-300',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gg_model = gensim.models.KeyedVectors.load_word2vec_format(DATA_DIR+\"gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = {}\n",
    "def gen_bow(x,bow):\n",
    "  for word in x.split(\" \"):\n",
    "    try:\n",
    "      bow[word] += 1\n",
    "    except:\n",
    "      bow[word] = 1\n",
    "  return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[\"review_cleaned\"].apply(lambda x: gen_bow(x,bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR+\"bow.pkl\",\"wb\") as file:\n",
    "    pickle.dump(bow, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coverage(wv, bow):\n",
    "  covered = {}\n",
    "  uncovered = {}\n",
    "  for word, count in bow.items():\n",
    "    try: # found in wv\n",
    "      temp = wv[word]\n",
    "      covered[word] = bow[word]\n",
    "    except: # if not found in wv\n",
    "      uncovered[word] = bow[word]\n",
    "  print('Found embeddings for {:.2%} of vocab'.format(len(covered) / len(bow)))\n",
    "  print('Found embeddings for  {:.2%} of all text'.format(sum(covered.values())/ sum(bow.values())))\n",
    "  result = sorted(uncovered.items(), key=lambda x: x[1])[::-1]\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_DIR+\"bow.pkl\",\"rb\") as file:\n",
    "    bow = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 47.71% of vocab\n",
      "Found embeddings for  98.35% of all text\n"
     ]
    }
   ],
   "source": [
    "uncovered = check_coverage(gg_model, bow)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google News Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check semantic similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_difference(w,v):\n",
    "  return np.sqrt(sum(np.square(w-v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `\"Cat\", \"Car\", and \"Bus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5739133148105315"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_difference(gg_model[\"cat\"],gg_model[\"car\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9155472320880684"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_difference(gg_model[\"bus\"],gg_model[\"car\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### King − Man + Woman = Queen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.298657801924729"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = gg_model[\"king\"]-gg_model[\"man\"]+gg_model[\"woman\"]\n",
    "compare_difference(pred,gg_model[\"queen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.479692373238762"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_difference(gg_model[\"queen\"],gg_model[\"king\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### excellent ∼ outstanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4881580884687127"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_difference(gg_model[\"excellent\"],gg_model[\"outstanding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.957787185080837"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_difference(gg_model[\"excellent\"],gg_model[\"terrible\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build my own Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sampled_df[\"review_cleaned\"].apply(lambda x: x.split()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "    def __init__(self, sentences):\n",
    "      self.sentences = sentences\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in self.sentences:\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = MyCorpus(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = gensim.models.Word2Vec(sentences=corpus, min_count=9, size=300, window=13)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check semantic similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### King − Man + Woman = Queen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-79-c0baaff80348>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  pred = my_model[\"king\"]-my_model[\"man\"]+my_model[\"woman\"]\n",
      "<ipython-input-79-c0baaff80348>:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  compare_difference(pred,my_model[\"queen\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.871180486922247"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = my_model[\"king\"]-my_model[\"man\"]+my_model[\"woman\"]\n",
    "compare_difference(pred,my_model[\"queen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-80-5fe7239160ae>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  compare_difference(my_model[\"queen\"],my_model[\"king\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5191899898462256"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_difference(my_model[\"queen\"],my_model[\"king\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### excellent ∼ outstanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-81-d0bd3f31e48d>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  compare_difference(my_model[\"excellent\"],my_model[\"outstanding\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.07535627275851"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_difference(my_model[\"excellent\"],my_model[\"outstanding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-82-d357210032c4>:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  compare_difference(my_model[\"excellent\"],my_model[\"terrible\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.696851275335957"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_difference(my_model[\"excellent\"],my_model[\"terrible\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mean_embed(x, wv):\n",
    "  shp = (1,300)\n",
    "  result = []\n",
    "  tokens = x.split(\" \")\n",
    "  count = 0\n",
    "  for word in tokens:\n",
    "    try:\n",
    "      result.append(wv[word].reshape(shp))\n",
    "      count += 1\n",
    "    except:\n",
    "      continue\n",
    "  if len(result) == 0:\n",
    "    return np.zeros(shp).astype('float32')\n",
    "  return np.mean(result, axis=0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_cat_embed(x, wv, max_len=10):\n",
    "  shp = wv[\"king\"].shape\n",
    "  result = []\n",
    "  tokens = x.split(\" \")\n",
    "  count = 0\n",
    "  for word in tokens:\n",
    "    try:\n",
    "      result.append(wv[word].reshape(shp))\n",
    "      count += 1\n",
    "    except:\n",
    "      continue\n",
    "    if count==max_len:\n",
    "      break\n",
    "  if len(result) < max_len:\n",
    "    pad_len = max_len-len(result)\n",
    "    result += [np.zeros(shp) for i in range(pad_len)]\n",
    "  return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[\"mean_emb\"] = sampled_df[\"review_body\"].apply(lambda x: gen_mean_embed(x, gg_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[\"cat_emb\"] = sampled_df[\"review_body\"].apply(lambda x: gen_cat_embed(x, gg_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[\"rnn_emb\"] = sampled_df[\"review_body\"].apply(lambda x: gen_cat_embed(x, gg_model, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word2Vec(Dataset):\n",
    "    \n",
    "  def __init__(self, df, transform=None):\n",
    "      self.data = df\n",
    "      self.transform = transform\n",
    "      \n",
    "  def __len__(self):\n",
    "      return len(self.data)\n",
    "  \n",
    "  def __getitem__(self, index):\n",
    "      emb = self.data.iloc[index,0].astype('float32') #.reshape(())\n",
    "      label = self.data.iloc[index,1]\n",
    "      \n",
    "      if self.transform is not None:\n",
    "          image = self.transform(emb)\n",
    "          \n",
    "      return emb, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_test_loader(feature_df, batch_size=64):\n",
    "  data = Word2Vec(feature_df, transform=transforms.ToTensor())\n",
    "  train, val, test = random_split(data,[int(np.floor(len(feature_df)*0.6)),int(np.floor(len(feature_df)*0.2)),int(np.floor(len(feature_df)*0.2))])\n",
    "  train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size,\n",
    "    shuffle=True)\n",
    "  val_loader = torch.utils.data.DataLoader(val, batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "  test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, \n",
    "      shuffle=False)\n",
    "  return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(sampled_df[\"mean_emb\"], sampled_df[['label']], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "def evaluation(y_pred, y_true):\n",
    "    prc = precision_score(y_true, y_pred, average=None)\n",
    "    recall = recall_score(y_true, y_pred, average=None)\n",
    "    f1 = f1_score(y_true, y_pred, average=None)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    for cls in range(1,4):\n",
    "        print(f'<Class {cls}> Precision: {prc[cls-1]}, Recall: {recall[cls-1]}, F-1: {f1[cls-1]}')\n",
    "    print(f'<Overall Mean> Precision: {np.mean(prc)}, Recall: {np.mean(recall)}, F-1: {np.mean(f1)}, Accuracy: {np.mean(acc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Class 1> Precision: 0.536787040161998, Recall: 0.7958468851638729, F-1: 0.6411367529980853\n",
      "<Class 2> Precision: 0.5492424242424242, Recall: 0.5388999008919723, F-1: 0.5440220110055027\n",
      "<Class 3> Precision: 0.8935666982024598, Recall: 0.47617847239727756, F-1: 0.6212793948363756\n",
      "<Overall Mean> Precision: 0.6598653875356274, Recall: 0.6036417528177076, F-1: 0.6021460529466545, Accuracy: 0.60375\n"
     ]
    }
   ],
   "source": [
    "#best_seed = find_best_randseed(20)\n",
    "perceptron_md = Perceptron(tol=1e-3, random_state=0)\n",
    "perceptron_md.fit(np.stack(X_train), y_train.values.ravel())\n",
    "evaluation(perceptron_md.predict(np.stack(X_test)), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Class 1> Precision: 0.6834581347855684, Recall: 0.7535651738804103, F-1: 0.7168015230842456\n",
      "<Class 2> Precision: 0.6408713098308971, Recall: 0.554013875123885, F-1: 0.5942857142857142\n",
      "<Class 3> Precision: 0.7863060428849903, Recall: 0.813461053692967, F-1: 0.7996530789245447\n",
      "<Overall Mean> Precision: 0.7035451625004853, Recall: 0.7070133675657541, F-1: 0.7035801054315015, Accuracy: 0.70625\n"
     ]
    }
   ],
   "source": [
    "svm_md = LinearSVC(random_state=0, dual=False, C=0.05)\n",
    "svm_md.fit(np.stack(X_train), y_train.values.ravel())\n",
    "evaluation(svm_md.predict(np.stack(X_test)), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, loader, criterion):\n",
    "  test_loss = 0.0\n",
    "  correct_count = 0\n",
    "  model.eval()\n",
    "  for data, label in loader:\n",
    "    data.to(device)\n",
    "    label.to(device)\n",
    "    pred = model(data)\n",
    "    loss = criterion(pred, label)\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    correct_count += (pred.argmax(axis=1) == label).sum().item() \n",
    "  test_loss = test_loss/len(loader.dataset)\n",
    "  test_acc = correct_count/len(loader.dataset)\n",
    "  return test_loss, test_acc\n",
    "\n",
    "def train(model, train_loader, val_loader, test_loader, epoch_num, lr=0.01):\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  #optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "  weight_decay = 1e-4\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "  best_val_loss = np.inf\n",
    "  for epoch in range(epoch_num):\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for data, label in train_loader:\n",
    "      data.to(device)\n",
    "      label.to(device)\n",
    "      label = F.one_hot(label).float()\n",
    "      optimizer.zero_grad()\n",
    "      pred = model(data)\n",
    "      #print(pred.shape,label.shape)\n",
    "      loss = criterion(pred, label)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      train_loss += loss.item()*data.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    val_loss, val_acc = eval(model, val_loader, criterion)\n",
    "    #if epoch_num>10 and (epoch+1)%10 == 0:\n",
    "    print(f\"[Epoch {epoch+1}] Train Loss: {train_loss}\")\n",
    "    print(f\"[Epoch {epoch+1}] Val Loss: {val_loss}\")\n",
    "    if val_loss<best_val_loss:\n",
    "      best_val_loss = val_loss\n",
    "      torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': criterion,\n",
    "            }, DATA_DIR+'best_model.pth')\n",
    "  #print(best_val_loss)\n",
    "  checkpoint = torch.load(DATA_DIR+'best_model.pth')\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  test_loss, test_acc = eval(model, test_loader, criterion)\n",
    "  \n",
    "  print(f\"Test Loss: {test_loss}\")\n",
    "  print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardNeuralNetwork(nn.Module):\n",
    "  def __init__(self, input_size=300, dropout=0.2):\n",
    "    super(ForwardNeuralNetwork, self).__init__()\n",
    "    hidden_1 = 100\n",
    "    hidden_2 = 10\n",
    "    self.input_size = input_size\n",
    "    self.layer1 = nn.Linear(input_size, hidden_1)\n",
    "    self.layer2 = nn.Linear(hidden_1, hidden_2)\n",
    "    self.layer3 = nn.Linear(hidden_2, 3)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    x = x.view(-1, self.input_size)\n",
    "    x = F.relu(self.layer1(x))\n",
    "    x = self.dropout(x)\n",
    "    x = F.relu(self.layer2(x))\n",
    "    x = self.dropout(x)\n",
    "    x = self.layer3(x)\n",
    "    return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = gen_train_test_loader(sampled_df[[\"mean_emb\",\"label\"]].sample(60000), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.8137290114296807\n",
      "[Epoch 1] Val Loss: 0.7110626417795817\n",
      "[Epoch 2] Train Loss: 0.7230893446604411\n",
      "[Epoch 2] Val Loss: 0.6878786160151164\n",
      "[Epoch 3] Train Loss: 0.7082717269791498\n",
      "[Epoch 3] Val Loss: 0.6764097997347513\n",
      "[Epoch 4] Train Loss: 0.6940510704252455\n",
      "[Epoch 4] Val Loss: 0.6754676510492961\n",
      "[Epoch 5] Train Loss: 0.6834821257591247\n",
      "[Epoch 5] Val Loss: 0.6729069339434306\n",
      "[Epoch 6] Train Loss: 0.68030215660731\n",
      "[Epoch 6] Val Loss: 0.6731184935569763\n",
      "[Epoch 7] Train Loss: 0.6698232576052348\n",
      "[Epoch 7] Val Loss: 0.6558108727137247\n",
      "[Epoch 8] Train Loss: 0.6691948196093241\n",
      "[Epoch 8] Val Loss: 0.655287299156189\n",
      "[Epoch 9] Train Loss: 0.6626195336447822\n",
      "[Epoch 9] Val Loss: 0.6526960207621256\n",
      "[Epoch 10] Train Loss: 0.6559046327273051\n",
      "[Epoch 10] Val Loss: 0.6530044225056966\n",
      "0.6526960207621256\n",
      "Test Loss: 0.6445308755238851\n",
      "Test Accuracy: 0.71875\n"
     ]
    }
   ],
   "source": [
    "fnn = ForwardNeuralNetwork(dropout=0.2).to(device)\n",
    "train(fnn, train_loader, val_loader, test_loader, epoch_num=10, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = gen_train_test_loader(sampled_df[[\"cat_emb\",\"label\"]].sample(60000), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.8086624857584636\n",
      "[Epoch 1] Val Loss: 0.7154063116709392\n",
      "[Epoch 2] Train Loss: 0.7198042540550232\n",
      "[Epoch 2] Val Loss: 0.6951276100476583\n",
      "[Epoch 3] Train Loss: 0.6868773303031921\n",
      "[Epoch 3] Val Loss: 0.6905115958849589\n",
      "[Epoch 4] Train Loss: 0.6580080616209242\n",
      "[Epoch 4] Val Loss: 0.699057316939036\n",
      "[Epoch 5] Train Loss: 0.6290875034862095\n",
      "[Epoch 5] Val Loss: 0.6917047092119852\n",
      "[Epoch 6] Train Loss: 0.6017075389226277\n",
      "[Epoch 6] Val Loss: 0.6940470565954844\n",
      "[Epoch 7] Train Loss: 0.5759318087895712\n",
      "[Epoch 7] Val Loss: 0.7051472538312277\n",
      "[Epoch 8] Train Loss: 0.5507594144609239\n",
      "[Epoch 8] Val Loss: 0.7293712181250255\n",
      "[Epoch 9] Train Loss: 0.5260124085744222\n",
      "[Epoch 9] Val Loss: 0.7501742374897004\n",
      "[Epoch 10] Train Loss: 0.5027230452961392\n",
      "[Epoch 10] Val Loss: 0.7736876887480418\n",
      "0.6905115958849589\n",
      "Test Loss: 0.6847688097953797\n",
      "Test Accuracy: 0.6965\n"
     ]
    }
   ],
   "source": [
    "fnn = ForwardNeuralNetwork(input_size=300*10, dropout=0.3).to(device)\n",
    "train(fnn, train_loader, val_loader, test_loader, epoch_num=7, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0.2):\n",
    "        super(myRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.layer1 = nn.RNN(input_size, hidden_size, n_layers, batch_first=True, nonlinearity='relu')\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        x = x.view(batch_size, -1, self.input_size)\n",
    "        x, hidden = self.layer1(x, hidden)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x[:, -1, :])\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = gen_train_test_loader(test_df[[\"rnn_emb\",\"label\"]], batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 1.0802663766013252\n",
      "[Epoch 1] Val Loss: 0.9088628629048665\n",
      "[Epoch 2] Train Loss: 0.8709351355234782\n",
      "[Epoch 2] Val Loss: 0.8131041674613952\n",
      "[Epoch 3] Train Loss: 0.7944715034696791\n",
      "[Epoch 3] Val Loss: 0.773356876373291\n",
      "[Epoch 4] Train Loss: 0.7610397662056817\n",
      "[Epoch 4] Val Loss: 0.7353272897402445\n",
      "[Epoch 5] Train Loss: 0.7351154816415575\n",
      "[Epoch 5] Val Loss: 0.733051476319631\n",
      "[Epoch 6] Train Loss: 0.7148104082213508\n",
      "[Epoch 6] Val Loss: 0.6991502415339153\n",
      "[Epoch 7] Train Loss: 0.6982838567097982\n",
      "[Epoch 7] Val Loss: 0.6818477902412414\n",
      "[Epoch 8] Train Loss: 0.6869051894611783\n",
      "[Epoch 8] Val Loss: 0.6661720527013143\n",
      "[Epoch 9] Train Loss: 0.6735935222307841\n",
      "[Epoch 9] Val Loss: 0.6682776913642884\n",
      "[Epoch 10] Train Loss: 0.6611515500280593\n",
      "[Epoch 10] Val Loss: 0.6587955342928569\n",
      "[Epoch 11] Train Loss: 0.6552951300409106\n",
      "[Epoch 11] Val Loss: 0.6586754361788432\n",
      "[Epoch 12] Train Loss: 0.6543201027446323\n",
      "[Epoch 12] Val Loss: 0.6671794934272766\n",
      "[Epoch 13] Train Loss: 0.6488319368892246\n",
      "[Epoch 13] Val Loss: 0.6676867097218832\n",
      "[Epoch 14] Train Loss: 0.6386240679952834\n",
      "[Epoch 14] Val Loss: 0.6464987270037333\n",
      "[Epoch 15] Train Loss: 0.6339892355600992\n",
      "[Epoch 15] Val Loss: 0.6419109779993694\n",
      "0.6419109779993694\n",
      "Test Loss: 0.6373978192011516\n",
      "Test Accuracy: 0.728\n"
     ]
    }
   ],
   "source": [
    "rnn = myRNN(300, 20, 3, n_layers=1, dropout=0.2)\n",
    "rnn.to(device)\n",
    "train(rnn, train_loader, val_loader, test_loader, epoch_num=15, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0.2):\n",
    "        super(myGRU, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.layer1 = nn.GRU(input_size, hidden_size, n_layers, batch_first=True)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        x = x.view(batch_size, -1, self.input_size)\n",
    "        x, hidden = self.layer1(x, hidden)\n",
    "        x = self.dropout(x)\n",
    "        #x = x.contiguous().view(-1, self.hidden_dim)\n",
    "        x = self.layer2(x[:, -1, :])\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = gen_train_test_loader(sampled_df[[\"rnn_emb\",\"label\"]].sample(60000), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.9135241704516941\n",
      "[Epoch 1] Val Loss: 0.7000537357330322\n",
      "[Epoch 2] Train Loss: 0.6907125168906317\n",
      "[Epoch 2] Val Loss: 0.6515696303049723\n",
      "[Epoch 3] Train Loss: 0.6555210551685757\n",
      "[Epoch 3] Val Loss: 0.6322451899846395\n",
      "[Epoch 4] Train Loss: 0.6360423141055637\n",
      "[Epoch 4] Val Loss: 0.6234472675323486\n",
      "[Epoch 5] Train Loss: 0.6196180650658077\n",
      "[Epoch 5] Val Loss: 0.6086734843254089\n",
      "[Epoch 6] Train Loss: 0.6099090187284681\n",
      "[Epoch 6] Val Loss: 0.6082295484542847\n",
      "[Epoch 7] Train Loss: 0.6014884813096788\n",
      "[Epoch 7] Val Loss: 0.599206537882487\n",
      "[Epoch 8] Train Loss: 0.594681343237559\n",
      "[Epoch 8] Val Loss: 0.5931967439651489\n",
      "[Epoch 9] Train Loss: 0.5885585050582886\n",
      "[Epoch 9] Val Loss: 0.5993342148462931\n",
      "[Epoch 10] Train Loss: 0.5820469205644395\n",
      "[Epoch 10] Val Loss: 0.590727757136027\n",
      "[Epoch 11] Train Loss: 0.5759189331266615\n",
      "[Epoch 11] Val Loss: 0.5888265194892883\n",
      "[Epoch 12] Train Loss: 0.5716812987327575\n",
      "[Epoch 12] Val Loss: 0.5919062320391337\n",
      "[Epoch 13] Train Loss: 0.5651350673569573\n",
      "[Epoch 13] Val Loss: 0.5841524977684021\n",
      "[Epoch 14] Train Loss: 0.5623340030246311\n",
      "[Epoch 14] Val Loss: 0.5932335805892944\n",
      "[Epoch 15] Train Loss: 0.561972583770752\n",
      "[Epoch 15] Val Loss: 0.5890633014043172\n",
      "0.5841524977684021\n",
      "Test Loss: 0.6000938518047333\n",
      "Test Accuracy: 0.74075\n"
     ]
    }
   ],
   "source": [
    "rnn = myGRU(300, 20, 3, n_layers=1, dropout=0.3)\n",
    "rnn.to(device)\n",
    "train(rnn, train_loader, val_loader, test_loader, epoch_num=15, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, dropout=0.2):\n",
    "        super(myLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.layer1 = nn.LSTM(input_size, hidden_size, n_layers, batch_first=True)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        x = x.view(batch_size, -1, self.input_size)\n",
    "        x, hidden = self.layer1(x, hidden)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer2(x[:, -1, :])\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        h0 = torch.zeros((self.n_layers,batch_size,self.hidden_size)).to(device)\n",
    "        c0 = torch.zeros((self.n_layers,batch_size,self.hidden_size)).to(device)\n",
    "        hidden = (h0,c0)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, test_loader = gen_train_test_loader(sampled_df[[\"rnn_emb\",\"label\"]].sample(60000), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] Train Loss: 0.8904835794766744\n",
      "[Epoch 1] Val Loss: 0.7527339668273926\n",
      "[Epoch 2] Train Loss: 0.7216494943300883\n",
      "[Epoch 2] Val Loss: 0.7012647609710694\n",
      "[Epoch 3] Train Loss: 0.6794473994572957\n",
      "[Epoch 3] Val Loss: 0.6808966921170553\n",
      "[Epoch 4] Train Loss: 0.6562810870276558\n",
      "[Epoch 4] Val Loss: 0.6736346255938213\n",
      "[Epoch 5] Train Loss: 0.6380674528545803\n",
      "[Epoch 5] Val Loss: 0.6466740821202596\n",
      "[Epoch 6] Train Loss: 0.6264161426756117\n",
      "[Epoch 6] Val Loss: 0.6452412053743998\n",
      "[Epoch 7] Train Loss: 0.6166972374386258\n",
      "[Epoch 7] Val Loss: 0.6355683681170146\n",
      "[Epoch 8] Train Loss: 0.6050843118561638\n",
      "[Epoch 8] Val Loss: 0.6251179626782735\n",
      "[Epoch 9] Train Loss: 0.6000131556193034\n",
      "[Epoch 9] Val Loss: 0.6296871143976848\n",
      "[Epoch 10] Train Loss: 0.5929494455125597\n",
      "[Epoch 10] Val Loss: 0.628282518227895\n",
      "[Epoch 11] Train Loss: 0.5872453300688002\n",
      "[Epoch 11] Val Loss: 0.6162628966967265\n",
      "[Epoch 12] Train Loss: 0.5822600102424622\n",
      "[Epoch 12] Val Loss: 0.620447011311849\n",
      "[Epoch 13] Train Loss: 0.5773513350221846\n",
      "[Epoch 13] Val Loss: 0.6123779908816019\n",
      "[Epoch 14] Train Loss: 0.5712117629051209\n",
      "[Epoch 14] Val Loss: 0.6084766181310018\n",
      "[Epoch 15] Train Loss: 0.5667681210835774\n",
      "[Epoch 15] Val Loss: 0.6166614745457967\n",
      "0.6084766181310018\n",
      "Test Loss: 0.6062604201634725\n",
      "Test Accuracy: 0.7375833333333334\n"
     ]
    }
   ],
   "source": [
    "rnn = myLSTM(300, 20, 3, n_layers=1, dropout=0.2)\n",
    "rnn.to(device)\n",
    "train(rnn, train_loader, val_loader, test_loader, epoch_num=15, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
